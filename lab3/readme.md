# RISC-V 内存管理系统 (Memory Management) 实现与测试文档

## 1. 架构总览

本模块实现了基于 RISC-V **SV39** 协议的分页内存管理系统。它将物理内存的分配与虚拟地址空间的映射解耦，支持多核并发访问，并提供了完善的异常处理与资源回收机制。

---

## 2. 物理内存管理 (`pmem.c/h`)

### 2.1 区域划分 (Zoning)

为了优化内核与用户态的资源隔离，我们将物理内存划分为两个区域：

* **内核区域 (`kern_region`)**: 预留 4MB (1024页)，专门用于存放内核页表等关键数据。
* **用户区域 (`user_region`)**: 剩余物理内存（约 124MB），供进程数据使用。

### 2.2 管理机制

* **空闲链表**: 采用 O(1) 的链表算法。每个空闲物理页的前 8 字节存储指向下一页的指针。
* **自旋锁保护**: 每个区域拥有独立的 `spinlock`，确保多核同时申请内存时的数据一致性。
* **调试填充**: 释放内存时会用 `5` 填充页面，以便于在调试时快速识别野指针或非法访问。

---

## 3. 虚拟内存管理 (`vmem.c/h`)

系统实现了 SV39 三级页表转换逻辑，将 39 位虚拟地址映射为 56 位物理地址。

### 3.1 核心功能

* **按需建表 (`vm_getpte`)**: 遍历三级页表结构。若路径上的中间级页表尚未创建，则自动从 `pmem` 中分配。
* **灵活映射 (`vm_mappages`)**: 支持任意粒度的地址映射。支持配置 `PTE_R` (读)、`PTE_W` (写)、`PTE_X` (执行) 以及 `PTE_U` (用户模式访问) 权限。
* **资源回收 (`vm_destroy_pagetable`)**: 递归遍历整个页表树，不仅释放每一级页表自身占用的物理页，还可选择性地释放叶子节点指向的实际数据页。

---

## 4. 内存功能自动化测试 (`main.c`)

为了验证系统的稳定性，我们在内核初始化后运行了一套完整的内存压力与功能测试：

### 4.1 Test-1: 映射与查找测试

* **操作**: 映射 5 个物理页到不同的虚拟地址（包括跨越三级页表界限的大跨度映射）。
* **验证**: 使用 `vm_getpte` 检查映射后的物理地址是否与申请时一致。

### 4.2 Test-2: 权限与重新映射测试

* **操作**:
1. 释放一个已映射的虚拟地址 (`vm_unmappages`)。
2. 尝试重新将该地址映射到新的物理页，并修改权限（由 `R|W` 改为只读）。


* **验证**: 检查 `PTE` 中的权限位是否更新正确，确认 `unmap` 过程是否会造成内存泄漏。

### 4.3 Test-3: 资源回收与计数验证

* **场景**: 模拟进程销毁时的内存清理逻辑。
* **步骤**:
1. 记录销毁前的 `pmem_free_pages_count`。
2. 调用 `vm_destroy_pagetable(test_pgtbl, true)` 递归清理。
3. 再次获取空闲页总数。


* **预期结果**:
* 用户页计数应增加 3 页（因 Test-2 提前释放了 1 页，映射 5 页中的剩余页）。
* 内核页计数应增加 N 页（所有中间级页表及根页表所占用的空间）。



---

## 5. 关键 API 手册

| 函数 | 描述 |
| --- | --- |
| `pmem_init()` | 探测物理内存并构建初始空闲链表。 |
| `pmem_alloc(bool in_kernel)` | 从指定区域申请一个 4KB 页面。 |
| `vm_mappages(pgtbl, va, pa, sz, perm)` | 在指定页表中建立虚拟地址到物理地址的映射。 |
| `vm_unmappages(pgtbl, va, sz, free_pa)` | 取消映射，并根据参数决定是否释放对应的物理页。 |
| `vm_destroy_pagetable(pgtbl, free_leaf)` | 销毁整个页表树，释放页表占用的所有物理空间。 |

---

## 6. 运行示例

在引导成功后，控制台将输出测试报告：

```text
=== OS Lab: Memory Test ===
test-1: Mapping va 0 -> pa 0x8... Success
test-2: Unmap & Remap... Success
test-3: Destroying pagetable...
User page change: +3 (Expected: +3)
Kernel page change: +4 (Page tables freed)
All Memory Tests Passed!

```这是一份整合了物理内存、虚拟内存映射以及功能自动化测试的完整内存管理系统 README 文档。

---

# RISC-V 内存管理系统 (Memory Management) 实现与测试文档

## 1. 架构总览

本模块实现了基于 RISC-V **SV39** 协议的分页内存管理系统。它将物理内存的分配与虚拟地址空间的映射解耦，支持多核并发访问，并提供了完善的异常处理与资源回收机制。

---

## 2. 物理内存管理 (`pmem.c/h`)

### 2.1 区域划分 (Zoning)

为了优化内核与用户态的资源隔离，我们将物理内存划分为两个区域：

* **内核区域 (`kern_region`)**: 预留 4MB (1024页)，专门用于存放内核页表等关键数据。
* **用户区域 (`user_region`)**: 剩余物理内存（约 124MB），供进程数据使用。

### 2.2 管理机制

* **空闲链表**: 采用 O(1) 的链表算法。每个空闲物理页的前 8 字节存储指向下一页的指针。
* **自旋锁保护**: 每个区域拥有独立的 `spinlock`，确保多核同时申请内存时的数据一致性。
* **调试填充**: 释放内存时会用 `5` 填充页面，以便于在调试时快速识别野指针或非法访问。

---

## 3. 虚拟内存管理 (`vmem.c/h`)

系统实现了 SV39 三级页表转换逻辑，将 39 位虚拟地址映射为 56 位物理地址。

### 3.1 核心功能

* **按需建表 (`vm_getpte`)**: 遍历三级页表结构。若路径上的中间级页表尚未创建，则自动从 `pmem` 中分配。
* **灵活映射 (`vm_mappages`)**: 支持任意粒度的地址映射。支持配置 `PTE_R` (读)、`PTE_W` (写)、`PTE_X` (执行) 以及 `PTE_U` (用户模式访问) 权限。
* **资源回收 (`vm_destroy_pagetable`)**: 递归遍历整个页表树，不仅释放每一级页表自身占用的物理页，还可选择性地释放叶子节点指向的实际数据页。

---

## 4. 内存功能自动化测试 (`main.c`)

为了验证系统的稳定性，我们在内核初始化后运行了一套完整的内存压力与功能测试：

### 4.1 Test-1: 映射与查找测试

* **操作**: 映射 5 个物理页到不同的虚拟地址（包括跨越三级页表界限的大跨度映射）。
* **验证**: 使用 `vm_getpte` 检查映射后的物理地址是否与申请时一致。

### 4.2 Test-2: 权限与重新映射测试

* **操作**:
1. 释放一个已映射的虚拟地址 (`vm_unmappages`)。
2. 尝试重新将该地址映射到新的物理页，并修改权限（由 `R|W` 改为只读）。


* **验证**: 检查 `PTE` 中的权限位是否更新正确，确认 `unmap` 过程是否会造成内存泄漏。

### 4.3 Test-3: 资源回收与计数验证

* **场景**: 模拟进程销毁时的内存清理逻辑。
* **步骤**:
1. 记录销毁前的 `pmem_free_pages_count`。
2. 调用 `vm_destroy_pagetable(test_pgtbl, true)` 递归清理。
3. 再次获取空闲页总数。


* **预期结果**:
* 用户页计数应增加 3 页（因 Test-2 提前释放了 1 页，映射 5 页中的剩余页）。
* 内核页计数应增加 N 页（所有中间级页表及根页表所占用的空间）。



---

## 5. 关键 API 手册

| 函数 | 描述 |
| --- | --- |
| `pmem_init()` | 探测物理内存并构建初始空闲链表。 |
| `pmem_alloc(bool in_kernel)` | 从指定区域申请一个 4KB 页面。 |
| `vm_mappages(pgtbl, va, pa, sz, perm)` | 在指定页表中建立虚拟地址到物理地址的映射。 |
| `vm_unmappages(pgtbl, va, sz, free_pa)` | 取消映射，并根据参数决定是否释放对应的物理页。 |
| `vm_destroy_pagetable(pgtbl, free_leaf)` | 销毁整个页表树，释放页表占用的所有物理空间。 |

---

